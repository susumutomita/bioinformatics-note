# 歪んだカジノから隠れマルコフモデルへ：数学的定式化（超詳細版）

## 🎯 まず、この講義で何を学ぶのか

最終ゴール：**隠れマルコフモデル（HMM）の数学的構造を完全理解し、確率計算の仕組みを習得する**

でも、ちょっと待ってください。そもそもなぜ「隠れ」マルコフモデルなの。
実は、**観察できるのは表面的な現象だけで、その背後にある真の状態は見えない**という現実世界の本質を数学的にモデル化したものなんです。

## 🤔 ステップ0：なぜ数学的定式化が必要なのか

### 0-1. 前回の限界

```
前回：スライディングウィンドウ法
問題点：
- 窓サイズが恣意的
- 矛盾する判定
- 全体の確率を考慮していない
```

### 0-2. HMMによる革新

```
HMM：統一的な確率モデル
利点：
- 数学的に厳密
- 全体最適化可能
- あらゆる問題に応用可能
```

## 📖 ステップ1：ディーラーを「機械」として考える

### 1-1. ディーラーの振る舞いをモデル化

```python
class HMMDealer:
    """ディーラーを状態機械として表現"""

    def __init__(self):
        self.hidden_states = ["Fair", "Biased"]  # 隠れ状態
        self.current_state = None  # 現在の状態（観察者には見えない）

    def emit_symbol(self):
        """現在の状態に応じてシンボルを放出"""
        # 観察者が見えるのはこの結果だけ
        return "H" or "T"

    def transition(self):
        """次の状態への遷移"""
        # 観察者には見えない内部処理
        self.current_state = next_state
```

### 1-2. 2つの重要な決定

機械は各ステップで2つの決定を下す：

1. **どのシンボルを出すか**（放出）
2. **次にどの状態へ移るか**（遷移）

## 📖 ステップ2：HMMの4つの構成要素

### 2-1. 正式な定義

```python
class HiddenMarkovModel:
    """HMMの完全な定義"""

    def __init__(self):
        # 1. 放出シンボルのアルファベット
        self.symbols = ["H", "T"]  # 表と裏

        # 2. 隠れ状態の集合
        self.states = ["F", "B"]  # Fair, Biased

        # 3. 遷移確率行列
        self.transitions = {
            ("F", "F"): 0.9,  # FからFへ
            ("F", "B"): 0.1,  # FからBへ
            ("B", "F"): 0.1,  # BからFへ
            ("B", "B"): 0.9   # BからBへ
        }

        # 4. 放出確率行列
        self.emissions = {
            ("F", "H"): 0.5,  # Fから表
            ("F", "T"): 0.5,  # Fから裏
            ("B", "H"): 0.75, # Bから表
            ("B", "T"): 0.25  # Bから裏
        }
```

### 2-2. なぜこの4要素が必要か

```
観察できるもの：シンボル列（HHTHHTT...）
知りたいもの：状態列（FFFBBB...）

必要な情報：
- 何が出るか → 放出確率
- どう変わるか → 遷移確率
```

## 📖 ステップ3：遷移確率行列の理解

### 3-1. 行列で表現すると

```
        次の状態
        F     B
現  F [ 0.9   0.1 ]
状  B [ 0.1   0.9 ]
態
```

### 3-2. 視覚的に理解

```
   0.9 ┌─┐
   ┌──→│F│←──┐ 0.1
   │   └─┘   │
   │    ↓     │
0.1│    ↓0.1  │0.9
   │    ↓     │
   │   ┌─┐   │
   └───│B│───┘
    0.9└─┘
```

**ポイント**：各行の合計は必ず1（確率の法則）

## 📖 ステップ4：放出確率行列の理解

### 4-1. 行列で表現すると

```
        放出シンボル
        H     T
状  F [ 0.5   0.5  ]  # フェア
態  B [ 0.75  0.25 ]  # バイアス
```

### 4-2. 直感的理解

```python
def emit_probability(state, symbol):
    """状態から特定シンボルが出る確率"""
    if state == "Fair":
        # フェアコインは五分五分
        return 0.5

    else:  # Biased
        # バイアスコインは表が出やすい
        if symbol == "H":
            return 0.75
        else:
            return 0.25
```

## 📖 ステップ5：隠れ経路（Hidden Path）の概念

### 5-1. 隠れ経路とは

```
観察：HHTHHT（見える）
    ↑
隠れ経路：FFFBBB（見えない。推定したい）
```

### 5-2. 数学的表記

```python
# πを隠れ経路とする
π = ["F", "F", "F", "B", "B", "B"]

# Xを観察されたシンボル列
X = ["H", "H", "T", "H", "H", "T"]
```

## 📖 ステップ6：確率P(X, π)の計算

### 6-1. 何を計算するのか

「HMMが経路πをたどって文字列Xを放出する確率」

### 6-2. ステップバイステップの計算

```python
def calculate_probability(X, π):
    """P(X, π)を計算"""

    # 初期確率（最初の状態になる確率）
    prob = 0.5  # F, Bどちらも等確率と仮定

    # 各ステップで確率を掛け合わせる
    for i in range(len(X)):
        # 放出確率
        prob *= emission_prob(π[i], X[i])

        # 遷移確率（最後以外）
        if i < len(X) - 1:
            prob *= transition_prob(π[i], π[i+1])

    return prob
```

## 📖 ステップ7：具体例で計算してみよう

### 7-1. 例：X = "HTT", π = "FFB"

```
ステップ1：初期確率
P(F at start) = 0.5

ステップ2：Fから"H"を放出
P(H|F) = 0.5

ステップ3：FからFへ遷移
P(F→F) = 0.9

ステップ4：Fから"T"を放出
P(T|F) = 0.5

ステップ5：FからBへ遷移
P(F→B) = 0.1

ステップ6：Bから"T"を放出
P(T|B) = 0.25

全体の確率 = 0.5 × 0.5 × 0.9 × 0.5 × 0.1 × 0.25
          = 0.0028125
```

### 7-2. なぜこんな小さな値になるのか

```python
# 理由：多くの可能性があるから
total_paths = 2**n  # n: 文字列の長さ
# n=10なら1024通りの経路

# すべての確率を合計すると1
sum(P(X, π) for all X and π) = 1
```

## 📖 ステップ8：条件付き確率P(X|π)

### 8-1. 意味の違い

```
P(X, π)：Xとπがともに起こる確率
P(X|π)：πが与えられたときXが起こる確率
```

### 8-2. 重要な性質

```python
# πが決まれば、可能なXの確率の合計は1
sum(P(X|π) for all possible X) = 1

# 例：π = "FF"の場合
P("HH"|"FF") + P("HT"|"FF") + P("TH"|"FF") + P("TT"|"FF") = 1
# = 0.25 + 0.25 + 0.25 + 0.25 = 1
```

## 📖 ステップ9：計算の詳細な例

### 9-1. 完全な計算表

```
位置: 1    2    3    4    5    6    7    8    9    10
X:    T    H    T    H    H    T    T    H    T    H
π:    F    F    F    B    B    B    B    B    F    F

初期：P(F) = 0.5
位置1：P(T|F) = 0.5
遷移1→2：P(F→F) = 0.9
位置2：P(H|F) = 0.5
遷移2→3：P(F→F) = 0.9
位置3：P(T|F) = 0.5
遷移3→4：P(F→B) = 0.1  # 状態変化。
位置4：P(H|B) = 0.75
...
```

### 9-2. 確率の積

```python
total_prob = (
    0.5 *      # 初期
    0.5 * 0.9 * # 位置1と遷移
    0.5 * 0.9 * # 位置2と遷移
    0.5 * 0.1 * # 位置3と遷移（状態変化）
    0.75 * ...  # 以降続く
)
```

## 📖 ステップ10：なぜこの定式化が重要か

### 10-1. 問題の分離

```python
# P(X, π) = P(X|π) × P(π)

# つまり：
# 全体確率 = 放出の確率 × 経路の確率

# これにより問題が2つに分解される：
# 1. P(π)の計算（遷移確率のみ）
# 2. P(X|π)の計算（放出確率のみ）
```

### 10-2. 次のステップへの布石

```
現在：P(X, π)を計算できる
次の課題：最も確率の高いπを見つける
→ これがViterbiアルゴリズム
```

## 🎓 まとめ：今日学んだことを整理

### レベル1：表面的理解（これだけでもOK）

- HMMは4要素（シンボル、状態、遷移確率、放出確率）で定義
- 観察できるシンボル列から隠れた状態列を推定したい
- 確率は遷移確率と放出確率の積で計算

### レベル2：本質的理解（ここまで来たら素晴らしい）

- P(X, π) = P(X|π) × P(π)の分解により問題が単純化
- 遷移確率行列と放出確率行列が独立して扱える
- すべての可能性の確率を合計すると1になる数学的整合性

### レベル3：応用的理解（プロレベル）

- 条件付き確率と同時確率の使い分けの重要性
- 対数変換により極小値の計算を安定化できる
- この定式化が動的計画法への道を開く

## 🚀 次回予告

次回は、ついに**Viterbiアルゴリズム**の全貌が明らかに。
「なぜ動的計画法で最適経路が見つかるのか」
「どうやって計算量を劇的に削減するのか」

## 📚 重要な公式集

```python
# 基本公式
P(X, π) = P(π₀) × ∏ᵢ P(Xᵢ|πᵢ) × ∏ᵢ P(πᵢ→πᵢ₊₁)

# 分解公式
P(X, π) = P(X|π) × P(π)

# 正規化条件
Σ P(X, π) = 1  # すべてのXとπ
Σ P(X|π) = 1   # 固定πでのすべてのX
```

## 🔬 実験：HMM確率計算シミュレーター

```python
def hmm_probability_calculator(X, π):
    """HMMの確率を計算する実験"""

    # 遷移確率
    trans = {
        ("F", "F"): 0.9, ("F", "B"): 0.1,
        ("B", "F"): 0.1, ("B", "B"): 0.9
    }

    # 放出確率
    emit = {
        ("F", "H"): 0.5, ("F", "T"): 0.5,
        ("B", "H"): 0.75, ("B", "T"): 0.25
    }

    # 計算
    prob = 0.5  # 初期確率

    for i in range(len(X)):
        # 放出
        prob *= emit[(π[i], X[i])]

        # 遷移（最後以外）
        if i < len(X) - 1:
            prob *= trans[(π[i], π[i+1])]

    return prob

# テスト
X = "HHTH"
π = "FFBB"
result = hmm_probability_calculator(X, π)
print(f"P({X}, {π}) = {result}")
```

---

### 次回：「Viterbiアルゴリズム - 動的計画法が確率最大化問題を解く魔法」
