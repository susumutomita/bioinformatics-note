# ãƒˆãƒ©ã‚¤ã‹ã‚‰æ¥å°¾è¾ãƒ„ãƒªãƒ¼ã¸ï¼šã‚²ãƒãƒ æ¤œç´¢ã®é©å‘½ï¼ˆè¶…è©³ç´°ç‰ˆï¼‰

## ğŸ¯ ã¾ãšã€ã“ã®è¬›ç¾©ã§ä½•ã‚’å­¦ã¶ã®ã‹

æœ€çµ‚ã‚´ãƒ¼ãƒ«ï¼š**ã‚²ãƒãƒ å…¨ä½“ã‚’åŠ¹ç‡çš„ã«è¡¨ç¾ã™ã‚‹ã€Œæ¥å°¾è¾ãƒ„ãƒªãƒ¼ã€ã‚’ç†è§£ã—ã€ã©ã‚“ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã§ã‚‚ç¬æ™‚ã«æ¤œç´¢ã§ãã‚‹é­”æ³•ã®ã‚ˆã†ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’ãƒã‚¹ã‚¿ãƒ¼ã™ã‚‹**

ã§ã‚‚ã€ã¡ã‚‡ã£ã¨å¾…ã£ã¦ãã ã•ã„ã€‚å‰å›å­¦ã‚“ã ãƒˆãƒ©ã‚¤ã¯ç´ æ™´ã‚‰ã—ã„æŠ€è¡“ã§ã—ãŸã€‚ãªã®ã«ã€ãªãœæ–°ã—ã„ãƒ‡ãƒ¼ã‚¿æ§‹é€ ãŒå¿…è¦ãªã‚“ã§ã—ã‚‡ã†ï¼Ÿ

å®Ÿã¯ã€ãƒˆãƒ©ã‚¤ã«ã¯**è‡´å‘½çš„ãªå¼±ç‚¹**ãŒã‚ã£ãŸã‚“ã§ã™ã€‚ãã—ã¦ã€ãã®å¼±ç‚¹ã‚’å…‹æœã™ã‚‹éç¨‹ã§ã€**ãƒã‚¤ã‚ªã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹å²ä¸Šæœ€ã‚‚é‡è¦ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®ä¸€ã¤**ãŒç”Ÿã¾ã‚Œã¾ã—ãŸã€‚

## ğŸ¤” ã‚¹ãƒ†ãƒƒãƒ—0ï¼šãªãœãƒˆãƒ©ã‚¤ã§ã¯ä¸ååˆ†ãªã®ï¼Ÿ

### 0-1. ãƒˆãƒ©ã‚¤ã®éš ã‚ŒãŸå•é¡Œã‚’ç™ºè¦‹ã—ã‚ˆã†

å‰å›ã€1000å€‹ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åŒæ™‚ã«æ¤œç´¢ã§ãã‚‹ãƒˆãƒ©ã‚¤ã‚’å­¦ã³ã¾ã—ãŸã€‚ç´ æ™´ã‚‰ã—ã„æˆæœã§ã—ãŸï¼ã§ã‚‚...

```python
# ãƒˆãƒ©ã‚¤ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’è¨ˆç®—ã—ã¦ã¿ã‚ˆã†
def calculate_trie_memory():
    # ä¾‹ï¼šåˆ¶é™é…µç´ èªè­˜é…åˆ—1000å€‹ã‚’æ¤œç´¢
    pattern_count = 1000
    average_pattern_length = 20  # å¡©åŸº

    # ãƒˆãƒ©ã‚¤ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡
    trie_memory = pattern_count * average_pattern_length
    print(f"ãƒˆãƒ©ã‚¤ã®ãƒ¡ãƒ¢ãƒª: ç´„{trie_memory:,}æ–‡å­—åˆ†")
    # å‡ºåŠ›: ãƒˆãƒ©ã‚¤ã®ãƒ¡ãƒ¢ãƒª: ç´„20,000æ–‡å­—åˆ†

    # ã§ã‚‚ã€ã‚²ãƒãƒ ã®é•·ã•ã¯ï¼Ÿ
    human_genome_length = 3_000_000_000  # 30å„„å¡©åŸº
    print(f"ãƒ’ãƒˆã‚²ãƒãƒ : {human_genome_length:,}å¡©åŸº")

    # å•é¡Œï¼šãƒ‘ã‚¿ãƒ¼ãƒ³ãŒå¤šã„ã¨...
    many_patterns = 100_000  # 10ä¸‡å€‹ã®ãƒ¢ãƒãƒ¼ãƒ•
    huge_memory = many_patterns * average_pattern_length
    print(f"10ä¸‡ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒˆãƒ©ã‚¤: {huge_memory:,}æ–‡å­—åˆ†")
    # ã“ã‚Œã¯ã‚²ãƒãƒ ã‚µã‚¤ã‚ºã«åŒ¹æ•µï¼
```

### 0-2. ç™ºæƒ³ã®å¤§è»¢æ›

ã“ã“ã§å¤©æ‰çš„ãªç™ºæƒ³ãŒç”Ÿã¾ã‚Œã¾ã—ãŸï¼š

```python
# å¾“æ¥ã®ç™ºæƒ³ï¼šãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒ‡ãƒ¼ã‚¿æ§‹é€ åŒ–
traditional_approach = """
ãƒ‘ã‚¿ãƒ¼ãƒ³ç¾¤ â†’ ãƒˆãƒ©ã‚¤æ§‹ç¯‰ â†’ ã‚²ãƒãƒ ã‚’ã‚¹ã‚­ãƒ£ãƒ³
ï¼ˆãƒã‚¹ã«ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä¹—ã›ã¦ã€ã‚²ãƒãƒ ã¨ã„ã†é“ã‚’èµ°ã‚‹ï¼‰
"""

# æ–°ã—ã„ç™ºæƒ³ï¼šã‚²ãƒãƒ ã‚’ãƒ‡ãƒ¼ã‚¿æ§‹é€ åŒ–ï¼
revolutionary_approach = """
ã‚²ãƒãƒ  â†’ ãƒ‡ãƒ¼ã‚¿æ§‹é€ åŒ– â†’ ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒç¬é–“ç§»å‹•
ï¼ˆé“ãã®ã‚‚ã®ã‚’æŠ˜ã‚ŠãŸãŸã‚“ã§ã€ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç›®çš„åœ°ã¸ãƒ†ãƒ¬ãƒãƒ¼ãƒˆï¼‰
"""
```

## ğŸ“– ã‚¹ãƒ†ãƒƒãƒ—1ï¼šæ¥å°¾è¾ï¼ˆã‚µãƒ•ã‚£ãƒƒã‚¯ã‚¹ï¼‰ã®åŸºæœ¬

### 1-1. ãã‚‚ãã‚‚æ¥å°¾è¾ã£ã¦ä½•ï¼Ÿ

```python
def show_all_suffixes(text):
    """
    æ–‡å­—åˆ—ã®ã™ã¹ã¦ã®æ¥å°¾è¾ã‚’è¡¨ç¤º
    """
    text = text + "$"  # çµ‚ç«¯è¨˜å·ã‚’è¿½åŠ 
    suffixes = []

    for i in range(len(text)):
        suffix = text[i:]
        suffixes.append((i, suffix))

    return suffixes

# å®Ÿé¨“ã—ã¦ã¿ã‚ˆã†
genome = "BANANA"
suffixes = show_all_suffixes(genome)
for pos, suffix in suffixes:
    print(f"ä½ç½®{pos}: {suffix}")

# å‡ºåŠ›:
# ä½ç½®0: BANANA$
# ä½ç½®1: ANANA$
# ä½ç½®2: NANA$
# ä½ç½®3: ANA$
# ä½ç½®4: NA$
# ä½ç½®5: A$
# ä½ç½®6: $
```

### 1-2. ãªãœæ¥å°¾è¾ãŒé‡è¦ãªã®ã‹ï¼Ÿ

```python
# é­”æ³•ã®æ€§è³ªï¼šä»»æ„ã®éƒ¨åˆ†æ–‡å­—åˆ—ã¯ã€å¿…ãšã©ã‚Œã‹ã®æ¥å°¾è¾ã®æ¥é ­è¾ï¼
def find_pattern_in_suffixes(text, pattern):
    """
    ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒæ¥å°¾è¾ã®æ¥é ­è¾ã¨ã—ã¦å­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
    """
    text = text + "$"

    for i in range(len(text)):
        suffix = text[i:]
        if suffix.startswith(pattern):
            print(f"ãƒ‘ã‚¿ãƒ¼ãƒ³'{pattern}'ã‚’ä½ç½®{i}ã§ç™ºè¦‹ï¼")
            print(f"  æ¥å°¾è¾: {suffix}")
            print(f"  ãƒãƒƒãƒéƒ¨åˆ†: {suffix[:len(pattern)]}")
            return i

    return -1

# ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
find_pattern_in_suffixes("BANANA", "ANA")
# å‡ºåŠ›: ãƒ‘ã‚¿ãƒ¼ãƒ³'ANA'ã‚’ä½ç½®1ã§ç™ºè¦‹ï¼
```

## ğŸ“– ã‚¹ãƒ†ãƒƒãƒ—2ï¼šæ¥å°¾è¾ãƒˆãƒ©ã‚¤ã®æ§‹ç¯‰

### 2-1. ã™ã¹ã¦ã®æ¥å°¾è¾ã‹ã‚‰ãƒˆãƒ©ã‚¤ã‚’ä½œã‚‹

```python
class SuffixTrieNode:
    def __init__(self):
        self.children = {}
        self.suffix_index = None  # ã“ã®è‘‰ãŒè¡¨ã™æ¥å°¾è¾ã®é–‹å§‹ä½ç½®

def build_suffix_trie(text):
    """
    æ¥å°¾è¾ãƒˆãƒ©ã‚¤ã®æ§‹ç¯‰
    """
    text = text + "$"
    root = SuffixTrieNode()

    # ã™ã¹ã¦ã®æ¥å°¾è¾ã‚’è¿½åŠ 
    for i in range(len(text)):
        current = root

        # æ¥å°¾è¾ã®å„æ–‡å­—ã‚’å‡¦ç†
        for j in range(i, len(text)):
            char = text[j]

            if char not in current.children:
                current.children[char] = SuffixTrieNode()

            current = current.children[char]

        # è‘‰ã«æ¥å°¾è¾ã®é–‹å§‹ä½ç½®ã‚’è¨˜éŒ²
        current.suffix_index = i

    return root

# å®Ÿé¨“
text = "BANANA"
suffix_trie = build_suffix_trie(text)
print("æ¥å°¾è¾ãƒˆãƒ©ã‚¤æ§‹ç¯‰å®Œäº†ï¼")
```

### 2-2. æ¥å°¾è¾ãƒˆãƒ©ã‚¤ã§ã®ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œç´¢

```python
def search_in_suffix_trie(suffix_trie, pattern):
    """
    æ¥å°¾è¾ãƒˆãƒ©ã‚¤ã§ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢
    """
    current = suffix_trie

    # ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¾¿ã‚‹
    for char in pattern:
        if char not in current.children:
            return []  # ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒå­˜åœ¨ã—ãªã„
        current = current.children[char]

    # ã“ã®ãƒãƒ¼ãƒ‰ä»¥ä¸‹ã®ã™ã¹ã¦ã®è‘‰ã‚’åé›†
    positions = []
    def collect_leaves(node):
        if node.suffix_index is not None:
            positions.append(node.suffix_index)
        for child in node.children.values():
            collect_leaves(child)

    collect_leaves(current)
    return positions

# ãƒ†ã‚¹ãƒˆ
positions = search_in_suffix_trie(suffix_trie, "ANA")
print(f"'ANA'ã®å‡ºç¾ä½ç½®: {positions}")
```

## ğŸ“– ã‚¹ãƒ†ãƒƒãƒ—3ï¼šå•é¡Œç™ºè¦šï¼ãƒ¡ãƒ¢ãƒªã®çˆ†ç™º

### 3-1. æ¥å°¾è¾ãƒˆãƒ©ã‚¤ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡

```python
def calculate_suffix_trie_memory(genome_length):
    """
    æ¥å°¾è¾ãƒˆãƒ©ã‚¤ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’è¨ˆç®—
    """
    # æœ€æ‚ªã®å ´åˆï¼šã™ã¹ã¦ã®æ¥å°¾è¾ã®é•·ã•ã®åˆè¨ˆ
    total_chars = 0
    for i in range(genome_length):
        suffix_length = genome_length - i + 1  # +1 for $
        total_chars += suffix_length

    # ã“ã‚Œã¯ n*(n+1)/2 = O(nÂ²)
    theoretical = genome_length * (genome_length + 1) // 2

    print(f"ã‚²ãƒãƒ é•·: {genome_length:,}")
    print(f"æ¥å°¾è¾ãƒˆãƒ©ã‚¤ã®ãƒ¡ãƒ¢ãƒª: {total_chars:,}æ–‡å­—")
    print(f"ç†è«–å€¤: {theoretical:,}æ–‡å­—")
    print(f"ãƒ¡ãƒ¢ãƒªè¤‡é›‘åº¦: O(nÂ²)")

    return total_chars

# æã‚ã—ã„ç¾å®Ÿ
calculate_suffix_trie_memory(1000)  # 1000å¡©åŸº
# å‡ºåŠ›: æ¥å°¾è¾ãƒˆãƒ©ã‚¤ã®ãƒ¡ãƒ¢ãƒª: 500,500æ–‡å­—

calculate_suffix_trie_memory(1_000_000)  # 100ä¸‡å¡©åŸº
# å‡ºåŠ›: æ¥å°¾è¾ãƒˆãƒ©ã‚¤ã®ãƒ¡ãƒ¢ãƒª: 500,000,500,000æ–‡å­—ï¼ˆï¼ï¼‰
```

### 3-2. ãªãœã“ã‚“ãªã«å¤§ãããªã‚‹ã®ï¼Ÿ

```python
def visualize_suffix_trie_problem():
    """
    æ¥å°¾è¾ãƒˆãƒ©ã‚¤ã®å•é¡Œã‚’è¦–è¦šåŒ–
    """
    text = "AAAA$"

    print("ãƒ†ã‚­ã‚¹ãƒˆ: AAAA$")
    print("\næ¥å°¾è¾:")
    print("  AAAA$ (5æ–‡å­—)")
    print("  AAA$  (4æ–‡å­—)")
    print("  AA$   (3æ–‡å­—)")
    print("  A$    (2æ–‡å­—)")
    print("  $     (1æ–‡å­—)")
    print(f"\nåˆè¨ˆ: {5+4+3+2+1} = 15æ–‡å­—")
    print(f"å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆé•·: 5æ–‡å­—")
    print(f"å€ç‡: 3å€ï¼")

    # ä¸€èˆ¬åŒ–
    n = 5
    total = n * (n + 1) // 2
    print(f"\nä¸€èˆ¬å¼: nÃ—(n+1)/2 = {n}Ã—{n+1}/2 = {total}")

visualize_suffix_trie_problem()
```

## ğŸ“– ã‚¹ãƒ†ãƒƒãƒ—4ï¼šæ•‘ä¸–ä¸»ã€Œæ¥å°¾è¾ãƒ„ãƒªãƒ¼ã€ã®ç™»å ´

### 4-1. ãƒ‘ã‚¹åœ§ç¸®ã®å¤©æ‰çš„ã‚¢ã‚¤ãƒ‡ã‚¢

```python
def compress_suffix_trie():
    """
    æ¥å°¾è¾ãƒˆãƒ©ã‚¤ã‚’åœ§ç¸®ã—ã¦æ¥å°¾è¾ãƒ„ãƒªãƒ¼ã¸
    """
    example = """
    åœ§ç¸®å‰ï¼ˆæ¥å°¾è¾ãƒˆãƒ©ã‚¤ï¼‰:
    root â†’ B â†’ A â†’ N â†’ A â†’ N â†’ A â†’ $
           â†“
           A â†’ N â†’ A â†’ N â†’ A â†’ $

    åœ§ç¸®å¾Œï¼ˆæ¥å°¾è¾ãƒ„ãƒªãƒ¼ï¼‰:
    root â†’ "BANANA$"
           â†“
           "ANANA$"

    åˆ†å²ã®ãªã„ãƒ‘ã‚¹ã‚’1ã¤ã®ã‚¨ãƒƒã‚¸ã«åœ§ç¸®ï¼
    """
    print(example)

compress_suffix_trie()
```

### 4-2. æ¥å°¾è¾ãƒ„ãƒªãƒ¼ã®å®Ÿè£…

```python
class SuffixTreeNode:
    def __init__(self):
        self.children = {}
        self.edge_label = ""  # ã‚¨ãƒƒã‚¸ã®ãƒ©ãƒ™ãƒ«ï¼ˆéƒ¨åˆ†æ–‡å­—åˆ—ï¼‰
        self.suffix_index = None

def compress_path(node, text):
    """
    åˆ†å²ã®ãªã„ãƒ‘ã‚¹ã‚’åœ§ç¸®
    """
    if len(node.children) == 1 and node.suffix_index is None:
        # åˆ†å²ãŒãªã„å ´åˆã€å­ãƒãƒ¼ãƒ‰ã¨çµåˆ
        child_char = list(node.children.keys())[0]
        child = node.children[child_char]

        # ã‚¨ãƒƒã‚¸ãƒ©ãƒ™ãƒ«ã‚’çµåˆ
        node.edge_label += child_char + child.edge_label
        node.children = child.children
        node.suffix_index = child.suffix_index

        # å†å¸°çš„ã«åœ§ç¸®ã‚’ç¶šã‘ã‚‹
        compress_path(node, text)

# å®Ÿéš›ã«ã¯ã€ã‚¨ãƒƒã‚¸ãƒ©ãƒ™ãƒ«ã®ä»£ã‚ã‚Šã«
# ãƒ†ã‚­ã‚¹ãƒˆã¸ã®ãƒã‚¤ãƒ³ã‚¿ï¼ˆé–‹å§‹ä½ç½®ã¨çµ‚äº†ä½ç½®ï¼‰ã‚’ä½¿ç”¨
class EfficientSuffixTreeEdge:
    def __init__(self, text, start, end):
        self.text = text  # å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã¸ã®å‚ç…§
        self.start = start  # éƒ¨åˆ†æ–‡å­—åˆ—ã®é–‹å§‹ä½ç½®
        self.end = end  # éƒ¨åˆ†æ–‡å­—åˆ—ã®çµ‚äº†ä½ç½®

    def get_label(self):
        return self.text[self.start:self.end]
```

## ğŸ“– ã‚¹ãƒ†ãƒƒãƒ—5ï¼šãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã®åŠ‡çš„æ”¹å–„

### 5-1. æ¥å°¾è¾ãƒ„ãƒªãƒ¼ã®ãƒ¡ãƒ¢ãƒªåˆ†æ

```python
def analyze_suffix_tree_memory():
    """
    æ¥å°¾è¾ãƒ„ãƒªãƒ¼ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’åˆ†æ
    """
    print("=== æ¥å°¾è¾ãƒ„ãƒªãƒ¼ã®ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ ===\n")

    # é‡è¦ãªäº‹å®Ÿ
    facts = """
    1. è‘‰ã®æ•° = ãƒ†ã‚­ã‚¹ãƒˆé•·ï¼ˆå„æ¥å°¾è¾ã«1ã¤ã®è‘‰ï¼‰
    2. å†…éƒ¨ãƒãƒ¼ãƒ‰ã®æ•° < ãƒ†ã‚­ã‚¹ãƒˆé•·
    3. ç·ãƒãƒ¼ãƒ‰æ•° < 2 Ã— ãƒ†ã‚­ã‚¹ãƒˆé•·
    4. å„ã‚¨ãƒƒã‚¸ã¯é–‹å§‹ãƒ»çµ‚äº†ä½ç½®ã®ã¿ä¿å­˜
    """
    print(facts)

    # ãƒ¡ãƒ¢ãƒªè¨ˆç®—
    def calculate_memory(n):
        leaves = n
        internal_nodes = n - 1  # æœ€æ‚ªã®å ´åˆ
        total_nodes = leaves + internal_nodes

        # å„ãƒãƒ¼ãƒ‰ã¯å›ºå®šã‚µã‚¤ã‚º
        node_size = 3  # ãƒã‚¤ãƒ³ã‚¿2ã¤ + ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        total_memory = total_nodes * node_size

        return {
            'leaves': leaves,
            'internal': internal_nodes,
            'total_nodes': total_nodes,
            'memory': total_memory,
            'complexity': 'O(n)'
        }

    # æ¯”è¼ƒ
    for size in [100, 1000, 1000000]:
        result = calculate_memory(size)
        print(f"\nã‚²ãƒãƒ é•· {size:,}:")
        print(f"  æ¥å°¾è¾ãƒˆãƒ©ã‚¤: O(nÂ²) = {size*size:,}")
        print(f"  æ¥å°¾è¾ãƒ„ãƒªãƒ¼: O(n) = {result['memory']:,}")
        print(f"  å‰Šæ¸›ç‡: {(size*size/result['memory']):.1f}å€")

analyze_suffix_tree_memory()
```

### 5-2. ãªãœO(n)ã§åã¾ã‚‹ã®ã‹ï¼Ÿ

```python
def why_linear_memory():
    """
    ç·šå½¢ãƒ¡ãƒ¢ãƒªã®ç†ç”±ã‚’èª¬æ˜
    """
    explanation = """
    === ãªãœæ¥å°¾è¾ãƒ„ãƒªãƒ¼ã¯O(n)ãƒ¡ãƒ¢ãƒªãªã®ã‹ ===

    1. è‘‰ã®æ•° = nï¼ˆæ¥å°¾è¾ã®æ•°ï¼‰
       - å„æ¥å°¾è¾ã¯å¿…ãš1ã¤ã®è‘‰ã§çµ‚ã‚ã‚‹

    2. å†…éƒ¨ãƒãƒ¼ãƒ‰ã¯åˆ†å²ç‚¹ã®ã¿
       - åˆ†å² = å…±é€šæ¥é ­è¾ã®çµ‚ã‚ã‚Š
       - åˆ†å²ã®æ•° â‰¤ n-1

    3. ã‚¨ãƒƒã‚¸ã¯æ–‡å­—åˆ—ã‚’ã‚³ãƒ”ãƒ¼ã—ãªã„
       - é–‹å§‹ä½ç½®ã¨çµ‚äº†ä½ç½®ã®ã¿ä¿å­˜
       - ä¾‹: "BANANA" â†’ (0, 6) ã ã‘

    4. åˆè¨ˆ: 2nå€‹æœªæº€ã®ãƒãƒ¼ãƒ‰ Ã— å›ºå®šã‚µã‚¤ã‚º = O(n)
    """
    print(explanation)

    # å…·ä½“ä¾‹ã§ç¢ºèª
    text = "MISSISSIPPI$"
    print(f"\nãƒ†ã‚­ã‚¹ãƒˆ: {text}")
    print(f"é•·ã•: {len(text)}")
    print(f"è‘‰ã®æ•°: {len(text)}")
    print(f"å†…éƒ¨ãƒãƒ¼ãƒ‰æ•°: æœ€å¤§{len(text)-1}")
    print(f"ç·ãƒãƒ¼ãƒ‰æ•°: æœ€å¤§{2*len(text)-1}")

why_linear_memory()
```

## ğŸ“– ã‚¹ãƒ†ãƒƒãƒ—6ï¼šé­”æ³•ã®ã‚ˆã†ãªæ§‹ç¯‰ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 

### 6-1. ã‚¦ãƒƒã‚³ãƒãƒ³ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 

```python
def ukkonen_algorithm_intro():
    """
    ã‚¦ãƒƒã‚³ãƒãƒ³ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ç´¹ä»‹
    """
    magic = """
    === ã‚¦ãƒƒã‚³ãƒãƒ³ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼ˆ1995å¹´ï¼‰===

    é©šãã®æ€§è³ªï¼š
    1. æ™‚é–“è¨ˆç®—é‡: O(n) - ç·šå½¢æ™‚é–“ï¼
    2. ç©ºé–“è¨ˆç®—é‡: O(n) - ç·šå½¢ãƒ¡ãƒ¢ãƒªï¼
    3. ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ§‹ç¯‰: æ–‡å­—ã‚’1ã¤ãšã¤è¿½åŠ å¯èƒ½

    ã©ã†ã‚„ã£ã¦ï¼Ÿ
    - ã€Œæš—é»™ã®æ¥å°¾è¾ãƒ„ãƒªãƒ¼ã€ã¨ã„ã†æ¦‚å¿µã‚’ä½¿ç”¨
    - ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒã‚¤ãƒ³ãƒˆã‚’å·§å¦™ã«ç®¡ç†
    - æ¥å°¾è¾ãƒªãƒ³ã‚¯ã§é«˜é€Ÿã‚¸ãƒ£ãƒ³ãƒ—

    çµæœï¼šæ¥å°¾è¾ãƒˆãƒ©ã‚¤ã‚’çµŒç”±ã›ãšã«
          ç›´æ¥æ¥å°¾è¾ãƒ„ãƒªãƒ¼ã‚’æ§‹ç¯‰ï¼
    """
    print(magic)

ukkonen_algorithm_intro()
```

### 6-2. ç°¡ç•¥åŒ–ã—ãŸæ§‹ç¯‰ä¾‹

```python
class SimpleSuffixTree:
    """
    ç°¡ç•¥åŒ–ã—ãŸæ¥å°¾è¾ãƒ„ãƒªãƒ¼ï¼ˆæ•™è‚²ç”¨ï¼‰
    """
    def __init__(self, text):
        self.text = text + "$"
        self.root = self._build()

    def _build(self):
        # å®Ÿéš›ã®ã‚¦ãƒƒã‚³ãƒãƒ³ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯è¤‡é›‘
        # ã“ã“ã§ã¯æ¦‚å¿µçš„ãªèª¬æ˜ã®ã¿
        root = SuffixTreeNode()

        for i in range(len(self.text)):
            # å„æ¥å°¾è¾ã‚’è¿½åŠ 
            self._add_suffix(root, i)

        # ãƒ‘ã‚¹åœ§ç¸®
        self._compress(root)

        return root

    def _add_suffix(self, node, start):
        # æ¥å°¾è¾ã‚’è¿½åŠ ï¼ˆç°¡ç•¥åŒ–ï¼‰
        pass

    def _compress(self, node):
        # ãƒ‘ã‚¹ã‚’åœ§ç¸®ï¼ˆç°¡ç•¥åŒ–ï¼‰
        pass

    def search(self, pattern):
        """
        ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œç´¢
        """
        current = self.root
        pattern_index = 0

        while pattern_index < len(pattern):
            found = False
            for edge_label, child in current.children.items():
                if pattern[pattern_index:].startswith(edge_label):
                    pattern_index += len(edge_label)
                    current = child
                    found = True
                    break

            if not found:
                return []  # ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒè¦‹ã¤ã‹ã‚‰ãªã„

        # ç¾åœ¨ã®ãƒãƒ¼ãƒ‰ä»¥ä¸‹ã®ã™ã¹ã¦ã®è‘‰ã‚’åé›†
        return self._collect_positions(current)
```

## ğŸ“– ã‚¹ãƒ†ãƒƒãƒ—7ï¼šå®Ÿä¸–ç•Œã§ã®å¿œç”¨

### 7-1. ã‚²ãƒãƒ ã‚¢ã‚»ãƒ³ãƒ–ãƒªã§ã®æ´»ç”¨

```python
def genome_assembly_with_suffix_tree():
    """
    æ¥å°¾è¾ãƒ„ãƒªãƒ¼ã‚’ä½¿ã£ãŸã‚²ãƒãƒ ã‚¢ã‚»ãƒ³ãƒ–ãƒª
    """
    class GenomeAssembler:
        def __init__(self, reads):
            # ã™ã¹ã¦ã®ãƒªãƒ¼ãƒ‰ã‚’é€£çµ
            self.combined = "$".join(reads)
            self.suffix_tree = SimpleSuffixTree(self.combined)

        def find_overlaps(self, min_overlap=10):
            """
            ãƒªãƒ¼ãƒ‰é–“ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ã‚’é«˜é€Ÿæ¤œå‡º
            """
            overlaps = []

            for read in reads:
                # ãƒªãƒ¼ãƒ‰ã®æ¥å°¾è¾ã‚’æ¤œç´¢
                for k in range(min_overlap, len(read)):
                    suffix = read[-k:]
                    positions = self.suffix_tree.search(suffix)

                    for pos in positions:
                        # ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ã‚’è¨˜éŒ²
                        overlaps.append({
                            'read1': read,
                            'suffix': suffix,
                            'position': pos
                        })

            return overlaps

# ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
reads = ["ATCGATCG", "TCGATCGA", "GATCGATC"]
assembler = GenomeAssembler(reads)
print("ãƒªãƒ¼ãƒ‰é–“ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ã‚’æ¤œå‡ºä¸­...")
```

### 7-2. ç¹°ã‚Šè¿”ã—é…åˆ—ã®æ¤œå‡º

```python
def find_repeats_with_suffix_tree(genome):
    """
    æ¥å°¾è¾ãƒ„ãƒªãƒ¼ã§ç¹°ã‚Šè¿”ã—é…åˆ—ã‚’æ¤œå‡º
    """
    tree = SimpleSuffixTree(genome)

    def find_internal_nodes_with_multiple_leaves(node, path=""):
        """
        è¤‡æ•°ã®è‘‰ã‚’æŒã¤å†…éƒ¨ãƒãƒ¼ãƒ‰ã‚’æ¢ã™
        ï¼ˆ= ç¹°ã‚Šè¿”ã—é…åˆ—ï¼‰
        """
        repeats = []

        if len(node.children) > 1:
            # ã“ã®ãƒãƒ¼ãƒ‰ã¾ã§ã®ãƒ‘ã‚¹ãŒç¹°ã‚Šè¿”ã—
            leaf_count = count_leaves(node)
            if leaf_count > 1:
                repeats.append({
                    'sequence': path,
                    'count': leaf_count
                })

        for edge, child in node.children.items():
            child_repeats = find_internal_nodes_with_multiple_leaves(
                child, path + edge
            )
            repeats.extend(child_repeats)

        return repeats

    return find_internal_nodes_with_multiple_leaves(tree.root)

# ãƒ†ã‚¹ãƒˆ
test_genome = "ATGATGATGATG"
repeats = find_repeats_with_suffix_tree(test_genome)
print(f"ç¹°ã‚Šè¿”ã—é…åˆ—: {repeats}")
```

## ğŸ“– ã‚¹ãƒ†ãƒƒãƒ—8ï¼šæ¥å°¾è¾ãƒ„ãƒªãƒ¼ vs ä»–ã®æ‰‹æ³•

### 8-1. æ€§èƒ½æ¯”è¼ƒ

```python
def performance_comparison():
    """
    å„æ‰‹æ³•ã®æ€§èƒ½æ¯”è¼ƒ
    """
    import pandas as pd

    comparison = pd.DataFrame({
        'æ‰‹æ³•': ['å˜ç´”æ¤œç´¢', 'ãƒˆãƒ©ã‚¤', 'æ¥å°¾è¾ãƒˆãƒ©ã‚¤', 'æ¥å°¾è¾ãƒ„ãƒªãƒ¼', 'BWT+FM'],
        'å‰å‡¦ç†æ™‚é–“': ['O(1)', 'O(Î£|Pi|)', 'O(nÂ²)', 'O(n)', 'O(n)'],
        'æ¤œç´¢æ™‚é–“': ['O(nm)', 'O(m)', 'O(m)', 'O(m)', 'O(m)'],
        'ãƒ¡ãƒ¢ãƒª': ['O(1)', 'O(Î£|Pi|)', 'O(nÂ²)', 'O(n)', 'O(n)'],
        'æœ€é©ãªç”¨é€”': [
            'ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒå°‘ãªã„',
            'è¤‡æ•°ãƒ‘ã‚¿ãƒ¼ãƒ³',
            'ç†è«–çš„èˆˆå‘³',
            'ä¸‡èƒ½',
            'å·¨å¤§ã‚²ãƒãƒ '
        ]
    })

    print(comparison.to_string(index=False))

    print("\nå‡¡ä¾‹:")
    print("n: ãƒ†ã‚­ã‚¹ãƒˆï¼ˆã‚²ãƒãƒ ï¼‰ã®é•·ã•")
    print("m: ãƒ‘ã‚¿ãƒ¼ãƒ³ã®é•·ã•")
    print("Î£|Pi|: ã™ã¹ã¦ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆè¨ˆé•·")

performance_comparison()
```

### 8-2. ã„ã¤æ¥å°¾è¾ãƒ„ãƒªãƒ¼ã‚’ä½¿ã†ã¹ãã‹

```python
def when_to_use_suffix_tree():
    """
    æ¥å°¾è¾ãƒ„ãƒªãƒ¼ã®ä½¿ç”¨æŒ‡é‡
    """
    guidelines = """
    === æ¥å°¾è¾ãƒ„ãƒªãƒ¼ã‚’ä½¿ã†ã¹ãå ´é¢ ===

    âœ… æœ€é©ãªå ´åˆ:
    1. åŒã˜ã‚²ãƒãƒ ã«å¯¾ã—ã¦å¤šæ•°ã®æ¤œç´¢ã‚’è¡Œã†
    2. æœ€é•·å…±é€šéƒ¨åˆ†æ–‡å­—åˆ—ã‚’è¦‹ã¤ã‘ãŸã„
    3. ã™ã¹ã¦ã®ç¹°ã‚Šè¿”ã—é…åˆ—ã‚’åˆ—æŒ™ã—ãŸã„
    4. ãƒ‘ã‚¿ãƒ¼ãƒ³ã®é•·ã•ãŒæ§˜ã€…

    âš ï¸ æ³¨æ„ãŒå¿…è¦ãªå ´åˆ:
    1. ãƒ¡ãƒ¢ãƒªãŒéå¸¸ã«é™ã‚‰ã‚Œã¦ã„ã‚‹
       â†’ BWT + FM-indexã‚’æ¤œè¨
    2. ã‚²ãƒãƒ ãŒé »ç¹ã«æ›´æ–°ã•ã‚Œã‚‹
       â†’ å‹•çš„ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’æ¤œè¨
    3. å˜ç´”ãªãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ã®ã¿
       â†’ KMPã‚„BMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ååˆ†ã‹ã‚‚

    ğŸ’¡ å®Ÿè£…ã®ãƒ’ãƒ³ãƒˆ:
    - å®Ÿè£…ã¯è¤‡é›‘ãªã®ã§ã€æ—¢å­˜ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨æ¨å¥¨
    - Python: suffix-trees, pysuffix
    - C++: SDSL library
    """
    print(guidelines)

when_to_use_suffix_tree()
```

## ğŸ“– ã‚¹ãƒ†ãƒƒãƒ—9ï¼šå®Ÿè£…ã®èª²é¡Œã¨è§£æ±ºç­–

### 9-1. å®Ÿè£…ä¸Šã®èª²é¡Œ

```python
def implementation_challenges():
    """
    æ¥å°¾è¾ãƒ„ãƒªãƒ¼å®Ÿè£…ã®èª²é¡Œ
    """
    challenges = {
        "ãƒ¡ãƒ¢ãƒªç®¡ç†": {
            "å•é¡Œ": "ãƒã‚¤ãƒ³ã‚¿ãŒå¤šãã€ãƒ¡ãƒ¢ãƒªãŒæ–­ç‰‡åŒ–",
            "è§£æ±º": "ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«ã‚„ã‚«ã‚¹ã‚¿ãƒ ã‚¢ãƒ­ã‚±ãƒ¼ã‚¿ã‚’ä½¿ç”¨"
        },
        "æ§‹ç¯‰ã®è¤‡é›‘ã•": {
            "å•é¡Œ": "ã‚¦ãƒƒã‚³ãƒãƒ³ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯ç†è§£ãŒå›°é›£",
            "è§£æ±º": "ã¾ãšå˜ç´”ãªå®Ÿè£…ã‹ã‚‰å§‹ã‚ã€æ®µéšçš„ã«æœ€é©åŒ–"
        },
        "å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿": {
            "å•é¡Œ": "ã‚²ãƒãƒ ãŒå¤§ãã™ãã¦ãƒ¡ãƒ¢ãƒªã«åã¾ã‚‰ãªã„",
            "è§£æ±º": "ãƒ‡ã‚£ã‚¹ã‚¯ãƒ™ãƒ¼ã‚¹ã®å®Ÿè£…ã‚„BWTã¸ã®ç§»è¡Œ"
        },
        "ä¸¦åˆ—åŒ–": {
            "å•é¡Œ": "æ§‹ç¯‰ã®ä¸¦åˆ—åŒ–ãŒå›°é›£",
            "è§£æ±º": "éƒ¨åˆ†çš„ãªä¸¦åˆ—åŒ–ã‚„è¿‘ä¼¼ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ "
        }
    }

    for challenge, details in challenges.items():
        print(f"\nã€{challenge}ã€‘")
        print(f"  å•é¡Œ: {details['å•é¡Œ']}")
        print(f"  è§£æ±º: {details['è§£æ±º']}")

implementation_challenges()
```

### 9-2. å®Ÿç”¨çš„ãªå®Ÿè£…ä¾‹

```python
class PracticalSuffixTree:
    """
    å®Ÿç”¨çš„ãªæ¥å°¾è¾ãƒ„ãƒªãƒ¼å®Ÿè£…ã®éª¨æ ¼
    """
    def __init__(self, text, alphabet_size=256):
        self.text = text + "$"
        self.n = len(self.text)
        self.alphabet_size = alphabet_size

        # ãƒãƒ¼ãƒ‰ãƒ—ãƒ¼ãƒ«ï¼ˆãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–ï¼‰
        self.node_pool = []
        self.edge_pool = []

        # çµ±è¨ˆæƒ…å ±
        self.stats = {
            'nodes': 0,
            'edges': 0,
            'memory_bytes': 0
        }

        self._build()

    def _build(self):
        """
        æœ€é©åŒ–ã•ã‚ŒãŸæ§‹ç¯‰
        """
        # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ï¼š
        # 1. ã‚µãƒ•ã‚£ãƒƒã‚¯ã‚¹ãƒªãƒ³ã‚¯ã‚’ä½¿ç”¨
        # 2. ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒã‚¤ãƒ³ãƒˆã‚’ç®¡ç†
        # 3. è¦å‰‡1,2,3ã‚’é©ç”¨ï¼ˆã‚¦ãƒƒã‚³ãƒãƒ³ï¼‰
        pass

    def search_all(self, pattern):
        """
        ã™ã¹ã¦ã®å‡ºç¾ä½ç½®ã‚’æ¤œç´¢
        """
        positions = []
        # O(|pattern|)æ™‚é–“ã§æ¤œç´¢
        return positions

    def get_statistics(self):
        """
        ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®çµ±è¨ˆ
        """
        return self.stats

    def longest_repeated_substring(self):
        """
        æœ€é•·ç¹°ã‚Šè¿”ã—éƒ¨åˆ†æ–‡å­—åˆ—ã‚’æ¤œå‡º
        """
        # æœ€æ·±ã®å†…éƒ¨ãƒãƒ¼ãƒ‰ã‚’æ¢ã™
        pass

    def serialize(self, filename):
        """
        ãƒ‡ã‚£ã‚¹ã‚¯ã¸ã®æ°¸ç¶šåŒ–
        """
        # æ¥å°¾è¾ãƒ„ãƒªãƒ¼ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        pass

    @staticmethod
    def deserialize(filename):
        """
        ãƒ‡ã‚£ã‚¹ã‚¯ã‹ã‚‰èª­ã¿è¾¼ã¿
        """
        # ä¿å­˜ã•ã‚ŒãŸæ¥å°¾è¾ãƒ„ãƒªãƒ¼ã‚’å¾©å…ƒ
        pass
```

## ğŸ“– ã‚¹ãƒ†ãƒƒãƒ—10ï¼šã•ã‚‰ãªã‚‹ç™ºå±•

### 10-1. ä¸€èˆ¬åŒ–æ¥å°¾è¾ãƒ„ãƒªãƒ¼

```python
def generalized_suffix_tree():
    """
    è¤‡æ•°æ–‡å­—åˆ—ã®ä¸€èˆ¬åŒ–æ¥å°¾è¾ãƒ„ãƒªãƒ¼
    """
    class GeneralizedSuffixTree:
        def __init__(self, strings):
            # è¤‡æ•°ã®æ–‡å­—åˆ—ã‚’ç‰¹æ®Šè¨˜å·ã§é€£çµ
            self.strings = strings
            self.combined = ""
            self.separators = []

            for i, s in enumerate(strings):
                self.combined += s + f"${i}"
                self.separators.append(f"${i}")

            # é€šå¸¸ã®æ¥å°¾è¾ãƒ„ãƒªãƒ¼ã‚’æ§‹ç¯‰
            self.tree = SimpleSuffixTree(self.combined)

        def find_common_substrings(self, min_length=10):
            """
            è¤‡æ•°æ–‡å­—åˆ—ã«å…±é€šã™ã‚‹éƒ¨åˆ†æ–‡å­—åˆ—ã‚’æ¤œå‡º
            """
            # ç•°ãªã‚‹æ–‡å­—åˆ—ã‹ã‚‰ã®è‘‰ã‚’æŒã¤ãƒãƒ¼ãƒ‰ã‚’æ¢ã™
            pass

    # ä½¿ç”¨ä¾‹ï¼šè¤‡æ•°ã‚²ãƒãƒ ã®æ¯”è¼ƒ
    genomes = [
        "ATCGATCGATCG",
        "GATCGATCGATC",
        "TCGATCGATCGA"
    ]
    gst = GeneralizedSuffixTree(genomes)
    print("è¤‡æ•°ã‚²ãƒãƒ ã®å…±é€šé…åˆ—ã‚’æ¤œç´¢ä¸­...")

generalized_suffix_tree()
```

### 10-2. åœ§ç¸®æ¥å°¾è¾ãƒ„ãƒªãƒ¼

```python
def compressed_suffix_tree():
    """
    ã•ã‚‰ãªã‚‹ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–
    """
    optimizations = """
    === åœ§ç¸®æ¥å°¾è¾ãƒ„ãƒªãƒ¼ã®æŠ€è¡“ ===

    1. Enhanced Suffix Array (ESA)
       - é…åˆ—ãƒ™ãƒ¼ã‚¹ã§æ¥å°¾è¾ãƒ„ãƒªãƒ¼ã‚’è¡¨ç¾
       - ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŠ¹ç‡ãŒè‰¯ã„

    2. Compressed Suffix Array (CSA)
       - ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆæœ¨ã‚’ä½¿ç”¨
       - ãƒ¡ãƒ¢ãƒªã‚’ã•ã‚‰ã«å‰Šæ¸›

    3. FM-index
       - BWTãƒ™ãƒ¼ã‚¹
       - æ¥µé™ã¾ã§ã®åœ§ç¸®

    ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•:
    - ãƒ¡ãƒ¢ãƒªå‰Šæ¸› â†” æ¤œç´¢é€Ÿåº¦
    - æ§‹ç¯‰æ™‚é–“ â†” æ¤œç´¢åŠ¹ç‡
    """
    print(optimizations)

compressed_suffix_tree()
```

## ğŸ¯ å®Ÿè·µæ¼”ç¿’ï¼šå®Œå…¨ãªæ¥å°¾è¾ãƒ„ãƒªãƒ¼

```python
class CompleteSuffixTree:
    """
    æ•™è‚²ç”¨ã®å®Œå…¨ãªæ¥å°¾è¾ãƒ„ãƒªãƒ¼å®Ÿè£…
    """
    class Node:
        def __init__(self):
            self.children = {}
            self.start = -1
            self.end = -1
            self.suffix_link = None
            self.suffix_index = -1

    def __init__(self, text):
        self.text = text + "$"
        self.n = len(self.text)
        self.root = self.Node()
        self.active_node = self.root
        self.active_edge = -1
        self.active_length = 0
        self.remaining_suffix_count = 0
        self.leaf_end = -1
        self.internal_node_count = 0

        self._build_suffix_tree()

    def _build_suffix_tree(self):
        """
        ã‚¦ãƒƒã‚³ãƒãƒ³ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ç°¡ç•¥ç‰ˆ
        """
        for i in range(self.n):
            self._extend_suffix_tree(i)

    def _extend_suffix_tree(self, pos):
        """
        ä½ç½®posã®æ–‡å­—ã‚’è¿½åŠ 
        """
        # å®Ÿè£…ã®è©³ç´°ã¯çœç•¥ï¼ˆéå¸¸ã«è¤‡é›‘ï¼‰
        pass

    def search(self, pattern):
        """
        ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢ã—ã¦ã™ã¹ã¦ã®ä½ç½®ã‚’è¿”ã™
        """
        node = self.root
        i = 0

        while i < len(pattern):
            if pattern[i] in node.children:
                child = node.children[pattern[i]]
                edge_len = child.end - child.start + 1

                # ã‚¨ãƒƒã‚¸ä¸Šã‚’é€²ã‚€
                j = 0
                while j < edge_len and i < len(pattern):
                    if self.text[child.start + j] != pattern[i]:
                        return []  # ä¸ä¸€è‡´
                    i += 1
                    j += 1

                if i == len(pattern):
                    # ãƒ‘ã‚¿ãƒ¼ãƒ³å®Œå…¨ä¸€è‡´
                    return self._collect_leaves(child)

                node = child
            else:
                return []  # ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒè¦‹ã¤ã‹ã‚‰ãªã„

        return self._collect_leaves(node)

    def _collect_leaves(self, node):
        """
        ãƒãƒ¼ãƒ‰ä»¥ä¸‹ã®ã™ã¹ã¦ã®è‘‰ã®ä½ç½®ã‚’åé›†
        """
        positions = []

        if node.suffix_index >= 0:
            positions.append(node.suffix_index)

        for child in node.children.values():
            positions.extend(self._collect_leaves(child))

        return positions

    def print_statistics(self):
        """
        çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
        """
        print(f"ãƒ†ã‚­ã‚¹ãƒˆé•·: {self.n}")
        print(f"å†…éƒ¨ãƒãƒ¼ãƒ‰æ•°: {self.internal_node_count}")
        print(f"è‘‰ã®æ•°: {self.n}")
        print(f"ç·ãƒãƒ¼ãƒ‰æ•°: {self.internal_node_count + self.n}")
        print(f"ãƒ¡ãƒ¢ãƒªè¤‡é›‘åº¦: O(n)")

# ä½¿ç”¨ä¾‹
text = "MISSISSIPPI"
st = CompleteSuffixTree(text)
st.print_statistics()

# ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œç´¢
pattern = "ISS"
positions = st.search(pattern)
print(f"\n'{pattern}'ã®å‡ºç¾ä½ç½®: {positions}")
```

## ğŸ“ ã¾ã¨ã‚ï¼šä»Šæ—¥å­¦ã‚“ã ã“ã¨ã‚’æ•´ç†

### ãƒ¬ãƒ™ãƒ«1ï¼šè¡¨é¢çš„ç†è§£ï¼ˆã“ã‚Œã ã‘ã§ã‚‚OKï¼‰

- æ¥å°¾è¾ãƒ„ãƒªãƒ¼ã¯ã‚²ãƒãƒ å…¨ä½“ã‚’åŠ¹ç‡çš„ã«è¡¨ç¾ã™ã‚‹ãƒ‡ãƒ¼ã‚¿æ§‹é€ 
- ã©ã‚“ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã§ã‚‚O(m)æ™‚é–“ã§æ¤œç´¢å¯èƒ½
- ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã¯O(n)ã§ç·šå½¢

### ãƒ¬ãƒ™ãƒ«2ï¼šæœ¬è³ªçš„ç†è§£ï¼ˆã“ã“ã¾ã§æ¥ãŸã‚‰ç´ æ™´ã‚‰ã—ã„ï¼‰

- æ¥å°¾è¾ãƒˆãƒ©ã‚¤ã®ãƒ‘ã‚¹åœ§ç¸®ã«ã‚ˆã‚Šæ¥å°¾è¾ãƒ„ãƒªãƒ¼ãŒç”Ÿã¾ã‚ŒãŸ
- ã‚¦ãƒƒã‚³ãƒãƒ³ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ç·šå½¢æ™‚é–“æ§‹ç¯‰ãŒå¯èƒ½
- ç¹°ã‚Šè¿”ã—é…åˆ—æ¤œå‡ºã‚„æœ€é•·å…±é€šéƒ¨åˆ†æ–‡å­—åˆ—ãªã©å¤šæ§˜ãªå¿œç”¨

### ãƒ¬ãƒ™ãƒ«3ï¼šå¿œç”¨çš„ç†è§£ï¼ˆãƒ—ãƒ­ãƒ¬ãƒ™ãƒ«ï¼‰

- å®Ÿè£…ã®æœ€é©åŒ–æŠ€è¡“ï¼ˆãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«ã€ã‚µãƒ•ã‚£ãƒƒã‚¯ã‚¹ãƒªãƒ³ã‚¯ï¼‰
- ä¸€èˆ¬åŒ–æ¥å°¾è¾ãƒ„ãƒªãƒ¼ã§è¤‡æ•°é…åˆ—ã®æ¯”è¼ƒ
- BWTã‚„FM-indexã¸ã®ç™ºå±•ã¨ä½¿ã„åˆ†ã‘

## ğŸš€ æ¬¡å›äºˆå‘Š

æ¬¡å›ã¯ã€Œ**ãƒãƒ­ãƒ¼ã‚ºãƒ»ã‚¦ã‚£ãƒ¼ãƒ©ãƒ¼å¤‰æ›ï¼ˆBWTï¼‰**ã€ã‚’å­¦ã³ã¾ã™ã€‚

æ¥å°¾è¾ãƒ„ãƒªãƒ¼ãŒã€Œãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãªæ¤œç´¢ã€ã‚’å®Ÿç¾ã—ãŸã‚ˆã†ã«ã€BWTã¯ã€Œ**åœ§ç¸®ã—ãªãŒã‚‰æ¤œç´¢ã§ãã‚‹**ã€ã¨ã„ã†ã€ã•ã‚‰ã«é©šç•°çš„ãªæŠ€è¡“ã§ã™ã€‚

ãªã‚“ã¨ã€3GBã®ãƒ’ãƒˆã‚²ãƒãƒ ã‚’**500MBã«åœ§ç¸®ã—ãªãŒã‚‰é«˜é€Ÿæ¤œç´¢**ã§ãã‚‹ã‚“ã§ã™ï¼ãã®ç§˜å¯†ã¯ã€æ–‡å­—ã®ã€Œå·§å¦™ãªä¸¦ã¹æ›¿ãˆã€ã«ã‚ã‚Šã¾ã™ã€‚æ¬¡å›ã€ãã®é­”æ³•ã‚’è§£ãæ˜ã‹ã—ã¾ã—ã‚‡ã†ï¼
